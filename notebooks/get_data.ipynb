{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml, make_blobs # make_moons, make_circles\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI Iris Dataset - Binary Classification\n",
    "\n",
    "The objective is to predict the flower species, encoded as {0,1,2}.\n",
    "It is a small dataset containing only 4 features that is well-known in the ML community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "columns = [\n",
    "    \"Sepal Length\", \n",
    "    \"Sepal Width\", \n",
    "    \"Petal Length\", \n",
    "    \"Petal Width\", \n",
    "    \"Species\" # Target\n",
    "]\n",
    "df = pd.read_csv(url, header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/iris.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI Wine Dataset - Multiclass Classification\n",
    "\n",
    "The objective is to predict the wine type from different regions in Italy, encoded as {0,1,2}.  \n",
    "It is a small, well-structured dataset with 13 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "columns = [\n",
    "    \"Class\", # Target\n",
    "    \"Alcohol\", \n",
    "    \"Malic Acid\", \n",
    "    \"Ash\", \n",
    "    \"Alcalinity of Ash\",\n",
    "    \"Magnesium\", \n",
    "    \"Total Phenols\",\n",
    "    \"Flavanoids\",\n",
    "    \"Nonflavanoid Phenols\",\n",
    "    \"Proanthocyanins\",    \n",
    "    \"Color Intensity\", \n",
    "    \"Hue\", \n",
    "    \"OD280/OD315\", \n",
    "    \"Proline\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(url, header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/wine.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Boston Housing Dataset \n",
    "\n",
    "The objective is to predict the house price, using the median value of owner-occupied homes in $1000s, ```MEDV``` as the target.  \n",
    "It is one of the most widely used regression datasets in ML research with 13 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_openml(name=\"boston\", version=1, as_frame=True).frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/boston_housing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI Energy Efficiency Dataset - Multi Regression\n",
    "\n",
    "The objective is to predict energy efficiency of buildings through two targets: (i) ```Heating Load```, the amount of energy required for heating, and (ii) ```Cooling Load```, the amount of energy required for cooling.\n",
    "It is composed of 8 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\"\n",
    "df = pd.read_excel(url)\n",
    "df.columns = [\n",
    "    \"Relative Compactness\", \n",
    "    \"Surface Area\", \n",
    "    \"Wall Area\", \n",
    "    \"Roof Area\", \n",
    "    \"Overall Height\", \n",
    "    \"Orientation\", \n",
    "    \"Glazing Area\", \n",
    "    \"Glazing Area Distribution\", \n",
    "    \"Heating Load\", \n",
    "    \"Cooling Load\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/energy_efficiency.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000 # Small: 300 | Medium: 5000 | Large: 20000\n",
    "n_features = 4 # Small: 4 | Medium: 50 | Large: 300\n",
    "n_clusters = 3 # Small: 3 | Medium: 10 | Large: 50\n",
    "cluster_std = 1.0 # Small: 0.5 | Medium: 1.0 | Large: 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, centers = make_blobs(\n",
    "    n_samples=n_samples, # number of samples\n",
    "    n_features=n_features, # number of features\n",
    "    centers=n_clusters, # number of clusters (y contains the cluster labels)\n",
    "    cluster_std=cluster_std, # standard deviation of the clusters, the higher the more spread out the clusters are and the harder to separate them\n",
    "    center_box=(-10.0, 10.0), # the range of the centers\n",
    "    shuffle=True, # shuffle the data\n",
    "    random_state=42, # random state\n",
    "    return_centers=True # return the centers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=[f\"Feature {i+1}\" for i in range(X.shape[1])])\n",
    "# df[\"Species\"] = [f\"Cluster-{label}\" for label in y]\n",
    "df[\"Species\"] = [int(label)+1 for label in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "feature_columns = [col for col in df.columns if col != \"Species\"]\n",
    "df[feature_columns] = scaler.fit_transform(df[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"../data/blobs_{n_samples}_{n_features}_{n_clusters}_{cluster_std}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".torchsom_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
