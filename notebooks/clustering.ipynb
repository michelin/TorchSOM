{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torchsom.core import SOM\n",
    "from torchsom.visualization import SOMVisualizer, VisualizationConfig\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"../data/blobs_300_4_3_1.0.csv\",\n",
    ")\n",
    "blobs_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"../data/blobs_5000_50_3_1.0.csv\",\n",
    ")\n",
    "blobs_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"../data/blobs_5000_4_3_1.0.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = blobs_df.columns[:-1]  \n",
    "feature_names = feature_columns.to_list()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Create a tensor from the iris df and separate the features and the target\n",
    "2. Randomly shuffle the data\n",
    "3. Split the data into training and testing sets\n",
    "\"\"\"\n",
    "blobs_torch = torch.tensor(blobs_df.to_numpy(dtype=np.float32), device=device)\n",
    "all_features, all_targets = blobs_torch[:, :-1], blobs_torch[:, -1].long()\n",
    "\n",
    "\n",
    "shuffled_indices = torch.randperm(len(all_features), device=device)\n",
    "all_features, all_targets = all_features[shuffled_indices], all_targets[shuffled_indices]\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_count = int(train_ratio * len(all_features))\n",
    "train_features, train_targets = all_features[:train_count], all_targets[:train_count]\n",
    "test_features, test_targets = all_features[train_count:], all_targets[train_count:]\n",
    "\n",
    "print(train_features.shape, test_features.shape)\n",
    "print(train_targets.shape, test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchSOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = SOM(\n",
    "    x=25,\n",
    "    y=15,\n",
    "    sigma=1.45,\n",
    "    learning_rate=0.95,\n",
    "    neighborhood_order=3,\n",
    "    epochs=100,\n",
    "    batch_size=16, # 16 or train_features.shape[0]\n",
    "    topology=\"hexagonal\",\n",
    "    distance_function=\"euclidean\",\n",
    "    neighborhood_function=\"gaussian\",\n",
    "    num_features=all_features.shape[1],\n",
    "    lr_decay_function=\"asymptotic_decay\",\n",
    "    sigma_decay_function=\"asymptotic_decay\",\n",
    "    initialization_mode=\"pca\",\n",
    "    device=device,\n",
    "    random_seed=random_seed,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som.initialize_weights(\n",
    "    data=train_features,\n",
    "    mode=som.initialization_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QE, TE = som.fit(\n",
    "    data=train_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = SOMVisualizer(som=som, config=VisualizationConfig(save_format=\"pdf\"))\n",
    "save_path = f\"results/clustering/blob_{blobs_df.shape[0]}_{blobs_df.shape[1]}_{len(blobs_df['Species'].unique())}/{som.topology}\" # Set to None if you want a direct plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_training_errors(\n",
    "    quantization_errors=QE, \n",
    "    topographic_errors=TE, \n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_distance_map(save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_hit_map(\n",
    "    data=train_features,\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_classification_map(\n",
    "    data=train_features,\n",
    "    target=train_targets,\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_component_planes(\n",
    "    component_names=feature_names,\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = som.cluster(\n",
    "    method=\"hdbscan\", # hdbscan, kmeans, gmm\n",
    "    n_clusters=len(blobs_df['Species'].unique()),\n",
    "    feature_space=\"weights\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_cluster_map(\n",
    "    cluster_result=cluster,\n",
    "    save_path=save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_elbow_analysis(\n",
    "    max_k=10,\n",
    "    feature_space=\"weights\",\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "methods = [\"kmeans\", \"gmm\", \"hdbscan\"]\n",
    "feature_spaces = [\"weights\", \"positions\", \"combined\"]\n",
    "for method in methods:\n",
    "    for space in feature_spaces:\n",
    "        result = som.cluster(method=method, feature_space=space)\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_cluster_quality_comparison(\n",
    "    results_list=results,\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".torchsom_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
